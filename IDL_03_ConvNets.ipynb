{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffyelson/IntroductiontoDeepLearning/blob/main/IDL_03_ConvNets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IECA1vLqBZXp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "KsNvNVjNBZXw",
        "outputId": "5eb81fa5-7157-491a-c7eb-c4b925e79e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "*mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print(train_labels[0])\n",
        "plt.imshow(train_images[0], cmap=\"Greys_r\")\n",
        "\n",
        "# first difference: data is not reshaped to 784 anymore, but 28x28x1\n",
        "# note the 1 color channel!! this is important\n",
        "train_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
        "train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_images = test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255\n",
        "test_labels = test_labels.astype(np.int32)\n",
        "*\n",
        "test_data = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images, test_labels)).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RT58-w3BZXx"
      },
      "outputs": [],
      "source": [
        "train_steps = 2500\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    \n",
        "    #first convolution layer\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2,padding='same'),\n",
        "\n",
        "    #second convolution layer\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\",padding='same'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2,padding='same'),\n",
        "\n",
        "    #Flatten\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    #output layer\n",
        "    #tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.05)\n",
        "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVYP0T6IBZXy",
        "outputId": "10de0d1c-1c67-496c-eef4-63a6f2b545d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 Loss: 2.313544750213623 Accuracy: 0.125\n",
            "Step 100 Loss: 0.16334038972854614 Accuracy: 0.8121874928474426\n",
            "Step 200 Loss: 0.22055524587631226 Accuracy: 0.9414843916893005\n",
            "Step 300 Loss: 0.17726153135299683 Accuracy: 0.9446874856948853\n",
            "Step 400 Loss: 0.1333964765071869 Accuracy: 0.9568750262260437\n",
            "Step 500 Loss: 0.09879229962825775 Accuracy: 0.9512844681739807\n",
            "Step 600 Loss: 0.19768789410591125 Accuracy: 0.9612500071525574\n",
            "Step 700 Loss: 0.02787507325410843 Accuracy: 0.962109386920929\n",
            "Step 800 Loss: 0.058468542993068695 Accuracy: 0.9593750238418579\n",
            "Step 900 Loss: 0.11865168809890747 Accuracy: 0.9618750214576721\n",
            "Step 1000 Loss: 0.13916456699371338 Accuracy: 0.9696115255355835\n",
            "Step 1100 Loss: 0.06468477100133896 Accuracy: 0.962109386920929\n",
            "Step 1200 Loss: 0.05832729488611221 Accuracy: 0.9614843726158142\n",
            "Step 1300 Loss: 0.10697980225086212 Accuracy: 0.9560937285423279\n",
            "Step 1400 Loss: 0.030540069565176964 Accuracy: 0.958984375\n",
            "Step 1500 Loss: 0.16616326570510864 Accuracy: 0.9652255773544312\n",
            "Step 1600 Loss: 0.027660546824336052 Accuracy: 0.9652343988418579\n",
            "Step 1700 Loss: 0.13951316475868225 Accuracy: 0.9616405963897705\n",
            "Step 1800 Loss: 0.18652376532554626 Accuracy: 0.9609375\n",
            "Step 1900 Loss: 0.08741700649261475 Accuracy: 0.9628759622573853\n",
            "Step 2000 Loss: 0.125624418258667 Accuracy: 0.9645312428474426\n",
            "Step 2100 Loss: 0.060768261551856995 Accuracy: 0.963671863079071\n",
            "Step 2200 Loss: 0.1289234310388565 Accuracy: 0.9635156393051147\n",
            "Step 2300 Loss: 0.06002454459667206 Accuracy: 0.9595312476158142\n",
            "Step 2400 Loss: 0.08733845502138138 Accuracy: 0.9594298005104065\n",
            "Step 2500 Loss: 0.19740915298461914 Accuracy: 0.9587500095367432\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss = loss_fn(label_batch, logits)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "      \n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    train_acc_metric(label_batch, logits)\n",
        "    \n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Step {} Loss: {} Accuracy: {}\".format(step, loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()\n",
        "        \n",
        "del tape   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8IPQC4_BZXz",
        "outputId": "84ba9539-3edf-44ab-e38a-e7dbf4d98150"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test acc: 0.9610999822616577\n"
          ]
        }
      ],
      "source": [
        "# this is very convenient -- before, we usually had code that\n",
        "# evaluates the whole test set at once -- this won't work for\n",
        "# large datasets/models. With metrics, we can just iterate\n",
        "# over the data and the metric takes care of averaging etc.\n",
        "\n",
        "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJWc7Un27j4T"
      },
      "source": [
        "## ConvNets using CIFAR10 Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPg3k4S47t7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4153fa51-a27e-4ef5-d31e-51c234546550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "cifar10 = tf.keras.datasets.cifar10\n",
        "(train_images_c10, train_labels_c10), (test_images_c10, test_labels_c10) = cifar10.load_data()\n",
        "\n",
        "##Reference - https://www.tensorflow.org/tutorials/images/cnn\n",
        "\n",
        "train_labels_c10 = tf.keras.utils.to_categorical(train_labels_c10)\n",
        "test_labels_c10 = tf.keras.utils.to_categorical(test_labels_c10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOBuWq1I9sWL"
      },
      "outputs": [],
      "source": [
        "train_data_c10 = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images_c10.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, train_labels_c10.astype(np.int32)))\n",
        "train_data_c10 = train_data_c10.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "\n",
        "test_images_c10 = test_images_c10.reshape([-1, 32, 32, 3]).astype(np.float32) / 255\n",
        "test_labels_c10 = test_labels_c10.astype(np.int32)\n",
        "\n",
        "test_data_c10 = tf.data.Dataset.from_tensor_slices(\n",
        "    (test_images_c10, test_labels_c10)).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2As4twvIiQX"
      },
      "outputs": [],
      "source": [
        "train_steps = 2500\n",
        "\n",
        "\n",
        "model2 = tf.keras.Sequential([\n",
        "    \n",
        "    #first convolution layer\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",kernel_initializer='he_uniform',use_bias=True,input_shape=(32,32,3)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",kernel_initializer='he_uniform',use_bias=True,padding='SAME'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2),strides=2),\n",
        "\n",
        "    #second convolution layer\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",kernel_initializer='he_uniform',use_bias=True,padding='SAME'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",kernel_initializer='he_uniform',use_bias=True,padding='SAME'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2),strides=2),\n",
        "\n",
        "    #third convolution layer\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\",padding='SAME'),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\",padding='SAME'),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2),strides=2),\n",
        "\n",
        "    #Flatten\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    #output layer\n",
        "    tf.keras.layers.Dense(128,activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(10,activation=\"softmax\")\n",
        "])\n",
        "optimizer2 = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_fn2 = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "model2.build()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afCElJNfJXtp",
        "outputId": "9ae5070a-89b2-4eda-cf34-f9cede079d47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0 Loss: 2.342642068862915 Accuracy: 0.09375\n",
            "Step 100 Loss: 1.711855411529541 Accuracy: 0.27085936069488525\n",
            "Step 200 Loss: 1.6306042671203613 Accuracy: 0.408203125\n",
            "Step 300 Loss: 1.4589457511901855 Accuracy: 0.46976563334465027\n",
            "Step 400 Loss: 1.3054313659667969 Accuracy: 0.5134880542755127\n",
            "Step 500 Loss: 1.1809064149856567 Accuracy: 0.5500781536102295\n",
            "Step 600 Loss: 1.2064803838729858 Accuracy: 0.5669531226158142\n",
            "Step 700 Loss: 1.1401807069778442 Accuracy: 0.5860156416893005\n",
            "Step 800 Loss: 1.0931447744369507 Accuracy: 0.6029642224311829\n",
            "Step 900 Loss: 1.057612419128418 Accuracy: 0.6231250166893005\n",
            "Step 1000 Loss: 1.014563798904419 Accuracy: 0.6337500214576721\n",
            "Step 1100 Loss: 0.8469104766845703 Accuracy: 0.6321874856948853\n",
            "Step 1200 Loss: 1.184548258781433 Accuracy: 0.648760974407196\n",
            "Step 1300 Loss: 0.917815089225769 Accuracy: 0.6783593893051147\n",
            "Step 1400 Loss: 1.0334255695343018 Accuracy: 0.6756250262260437\n",
            "Step 1500 Loss: 0.861527681350708 Accuracy: 0.6789844036102295\n",
            "Step 1600 Loss: 0.7040868997573853 Accuracy: 0.6900094151496887\n",
            "Step 1700 Loss: 0.9182824492454529 Accuracy: 0.6982031464576721\n",
            "Step 1800 Loss: 0.8967548608779907 Accuracy: 0.70703125\n",
            "Step 1900 Loss: 0.8787373900413513 Accuracy: 0.7142187356948853\n",
            "Step 2000 Loss: 0.8231550455093384 Accuracy: 0.7229453921318054\n",
            "Step 2100 Loss: 0.9143762588500977 Accuracy: 0.7289062738418579\n",
            "Step 2200 Loss: 0.6985192894935608 Accuracy: 0.7235937714576721\n",
            "Step 2300 Loss: 0.8769201040267944 Accuracy: 0.7378906011581421\n",
            "Step 2400 Loss: 0.6080561876296997 Accuracy: 0.7537640929222107\n",
            "Step 2500 Loss: 0.8787451982498169 Accuracy: 0.7539843916893005\n"
          ]
        }
      ],
      "source": [
        "train_acc_metric_c10 = tf.keras.metrics.CategoricalAccuracy()\n",
        "\n",
        "for step, (image_batch, label_batch) in enumerate(train_data_c10):\n",
        "\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape4:\n",
        "        logits_c10 = model2(image_batch)\n",
        "        # loss format is generally: first argument targets, second argument outputs\n",
        "        loss_c10 = loss_fn2(label_batch, logits_c10)\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables_c10 = model2.trainable_variables\n",
        "    gradients_c10 = tape4.gradient(loss_c10, variables_c10)\n",
        "      \n",
        "    optimizer2.apply_gradients(zip(gradients_c10, variables_c10))\n",
        "    \n",
        "    train_acc_metric_c10(label_batch, logits_c10)\n",
        "    \n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Step {} Loss: {} Accuracy: {}\".format(step, loss_c10, train_acc_metric_c10.result()))\n",
        "        train_acc_metric_c10.reset_states()\n",
        "\n",
        "del tape4\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc_metric_c10 = tf.keras.metrics.CategoricalAccuracy()\n",
        "for image_batch, label_batch in test_data_c10:\n",
        "    test_acc_metric_c10(label_batch, model2(image_batch))\n",
        "print(\"Test acc: {}\".format(test_acc_metric_c10.result()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoMUF5QxcGg2",
        "outputId": "5ba373b1-dc82-4653-d7d8-e8df4899e32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc: 0.10000000149011612\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}